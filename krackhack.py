# -*- coding: utf-8 -*-
"""KrackHack.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rKJv7mRKAC3bWx3YZ6bx7NkcdLgadytj
"""

import pandas as pd
import warnings
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np

names=["NTPC","ONGC","POWERGRID","RELIANCE","SBIN","SHREECEM","SUNPHARMA","TATAMOTORS","TATASTEEL","TCS","TECHM","TITAN","ULTRACEMCO","UPL","VEDL","WIPRO","ZEEL","BHARTIARTL","BPCL","BRITANNIA","CIPLA","COALINDIA","DRREDDY","EICHERMOT","GAIL","GRASIM","HCLTECH","HDFC","HDFCBANK","HEROMOTOCO","HINDALCO","HINDUNILVR","ICICIBANK","INDUSINDBK","INFRATEL","INFY","IOC","ITC","JSWSTEEL","KOTAKBANK","LT","MARUTI","MM","NESTLEIND","ADANIPORTS","ASIANPAINT","AXISBANK","BAJAJ-AUTO","BAJAJFINSV","BAJFINANCE"]
datasets=[]
for n in names:
    df=pd.read_csv("Dataset/"+n+".csv")
    datasets.append(df)

with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=pd.errors.SettingWithCopyWarning)

    temp_dataset=[]
    for i in range(len(datasets)):
        temp_dataset.append(datasets[i].tail(2520))
        #print(names[i])
        #print(datasets[i].head())
        #print(len(datasets[i]))
    new_dataset=[]
    for i in range(len(temp_dataset)):
      new_dataset.append(temp_dataset[i].iloc[::30])
    for i in range(len(new_dataset)):
      new_dataset[i]["OpenNew"] = new_dataset[i]["Open"].shift(1)
      new_dataset[i].dropna(inplace=True)
    #print(new_dataset)

    for i in range(len(datasets)):
        new_dataset[i]["Profit"]=((new_dataset[i]["Close"]-new_dataset[i]["OpenNew"])/new_dataset[i]["OpenNew"])*100
    '''for i in range(len(datasets)):
        print(names[i])
        print(datasets[i].head())'''

    for i in range(len(datasets)):
        new_dataset[i]=new_dataset[i][["Date","Symbol","Profit"]]

    for i in range(len(datasets)):
        for j in range(5):
            new_dataset[i]["Profit_lag"+str(j+1)] = new_dataset[i]["Profit"].shift(j+1)

    for i in range(len(new_dataset)):
        new_dataset[i].dropna(inplace=True)
        print(names[i])
        '''corr=[]
        index=[]
        for j in range(5):
            correlation=new_dataset[i]["Profit"].corr(new_dataset[i]["Profit_lag"+str(j+1)])
            corr.append(correlation)
            if correlation<=0:
                index.append(j+1)
        print(f"Correlation from 1 to 5 is{corr}")
        for k in index:
            new_dataset[i].drop(columns="Profit_lag"+str(k),inplace=True)'''
        print(new_dataset[i])
        #print(len(new_dataset[i]))

for i in range(len(new_dataset)):
    d=new_dataset[i]
    d.to_csv(names[i]+'train.csv', index=False)
names.remove("INFRATEL")

# Creating a linear regression model
import matplotlib.pyplot as plt
dropped_cols=["Date","Symbol","Profit"]
models=[]
training_data=[]
testing_data=[]
profit_train=[]
profit_test=[]
dev={}
for name in names:
  model = LinearRegression()
  #print(name)
  df=pd.read_csv(name+"train.csv")
  #print(df.head())
  #plt.plot(df["Date"],df["Profit"])
  #plt.show()
  y = df["Profit"]
  dev[name]=np.std(y)
  X = df.drop(columns=dropped_cols)

  # Splitting the data into training and testing sets
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
  training_data.append(X_train)
  testing_data.append(X_test)
  profit_train.append(y_train)
  profit_test.append(y_test)
  #print(f"X_train dtype: {X_train.dtype}")
  #print(f"y_train dtype: {y_train.dtype}")
  # Training the model
  model.fit(X_train, y_train)
  #print(model)
  models.append(model)



# Making predictions on the test set
for i in range(len(training_data)):
  print(names[i])
  X_test=testing_data[i]
  y_test=profit_test[i]
  predictions = models[i].predict(X_test)
  #print(predictions)
  mse = mean_squared_error(y_test, predictions)
  print("Mean Squared Error:", mse)
#sorted_dev = dict(sorted(dev.items(), key=lambda item: item[1]))
#print(sorted_dev)
risk={}
for n in names:
  if dev[n]<10:
    risk[n]="LOW"
  elif dev[n]<15:
    risk[n]="MED"
  else:
    risk[n]="HIGH"
print(risk)
# Evaluating the model

profit_history=[]
for i in range(5):
  profit_history.append(float(input(f"Enter returns of {i+1} months before ")))
months=int(input("Enter number of months "))
money=int(input("Amount to be invested "))
t=np.array(profit_history)
ti=t.reshape(1,5)
X_test=ti
output = pd.DataFrame({'CompanyName': [],
                   'returns': [],
                   'risk': []})
for i in range(len(names)):
  #print(names[i])
  predictions = models[i].predict(X_test)
  new_data = {'CompanyName': names[i], 'returns': (predictions*months*money/100), 'risk': risk[names[i]]}
  output = output.append(new_data, ignore_index=True)
  #print(f"{names[i]} will provide {str(predictions)}% returns with risk {risk[names[i]]}")
print(output)
